{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aengmu_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+UwGHbzDpnluhK661PS05",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/NLP-Aengmu/blob/main/Aengmu_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtLYgO_OxLaU"
      },
      "source": [
        "# [ERROR 4] Korean(Hangul) breaking phenomenon Solution on Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce18aOPbxLkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c50ffb-d828-4605-9da9-2abacd9c4bf7"
      },
      "source": [
        "\"\"\" \n",
        "ERROR 4. plot \"Korean\" breaking phenomenon\n",
        "- Solution: Installing(↓) and setting(plt.rc('font', family='NanumBarunGothic')) Nanum font, after runtime restart\n",
        "\"\"\"\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20170925-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 4 dirs\n",
            "/usr/share/fonts/truetype/dejavu: caching, new cache contents: 22 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96hYYUFzcaxY"
      },
      "source": [
        "# Google Drive Local Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHqDHk2ucc7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a854d722-4d16-4ccb-b244-0d2a2fe6902f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgHeq1Zcb7M2"
      },
      "source": [
        "# Install Morpheme analyzer\n",
        "*   [Reference](https://soohee410.github.io/compare_tagger)\n",
        "*   [Install](https://sanghyu.tistory.com/170)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtYcWqVsb5Xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de97c344-3ca3-47ee-f092-c0fa759617a2"
      },
      "source": [
        "# okt, komoran, kkma\n",
        "# install konlpy (okt, komoran, kkma)\n",
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy\n",
        "\n",
        "# mecab (take a long time)\n",
        "# set env\n",
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# install konlpy (mecab)\n",
        "%%bash\n",
        "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "pip3 install /tmp/mecab-python-0.996"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 252 kB in 2s (117 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "openjdk-8-jdk is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1) (3.7.4.3)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n",
            "Processing /tmp/mecab-python-0.996\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py): started\n",
            "  Building wheel for mecab-python (setup.py): finished with status 'done'\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141816 sha256=6b4d3db47add4395e30c510d82322da80777357a77653e0228a9be62f9d03ec9\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "  Attempting uninstall: mecab-python\n",
            "    Found existing installation: mecab-python 0.996-ko-0.9.2\n",
            "    Uninstalling mecab-python-0.996-ko-0.9.2:\n",
            "      Successfully uninstalled mecab-python-0.996-ko-0.9.2\n",
            "    Running setup.py install for mecab-python: started\n",
            "    Running setup.py install for mecab-python: finished with status 'done'\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 8: fg: no job control\n",
            "bash: line 11: fg: no job control\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\n",
            "  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GobPxVERuegZ"
      },
      "source": [
        "# Error Solution\n",
        "\n",
        "1. TypeError: startJVM() got an unexpected keyword argument 'convertStrings' [(JVM)](https://gyulogs.tistory.com/130)\n",
        "2. NameError: name 'Tagger' is not defined [(Mecab)](https://sosomemo.tistory.com/31)\n",
        "3. ParserError: Error tokenizing data. C error [(Pandas)](https://mskim8717.tistory.com/82)\n",
        "4. plot \"Korean\" breaking phenomenon on Colab [(Matplotlib)](https://teddylee777.github.io/colab/colab-korean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpM2dDEuuesD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04199a3-cfe7-4cdc-9eef-7dc70cf0821d"
      },
      "source": [
        "\"\"\" \n",
        "ERROR 1. TypeError: startJVM() got an unexpected keyword argument 'convertStrings'\n",
        "- Solution: /usr/local/lib/python3.7/dist-packages/konlpy/jvm.py, 67 line (convertStrings=True) comments processing and save jvm.py before import pakage\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" \n",
        "ERROR 2. NameError: name 'Tagger' is not defined \n",
        "- Solution: Execute mecab.sh script (under code excute)\n",
        "\"\"\"\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connected to cloud.r-pro\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rHit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r                                                                               \rHit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease 47.5 kB/88.7 kB 54%] [Connecting to security.ubuntu.com (91.189\r0% [1 InRelease gpgv 242 kB] [2 InRelease 88.7 kB/88.7 kB 100%] [Connecting to \r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r                                                                               \rHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [6 InRelease 43.1 kB/74.6 kB 58%] [Connecting to s\r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 252 kB in 2s (114 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "openjdk-8-jdk is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1-py3 in /usr/local/lib/python3.7/dist-packages (0.5.5.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu59D-1sc93c"
      },
      "source": [
        "# Import\n",
        "*   [KoNLPy Reperence](https://konlpy-ko.readthedocs.io/ko/v0.4.3/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRaXnlVOWpot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5750709c-ce79-4258-8fce-314e6ee4c0ab"
      },
      "source": [
        "# import for MechineLearning\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import metrics, losses, callbacks\n",
        "from tensorflow.keras.optimizers import Adam, Adagrad, SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
        "\n",
        "# import Morpheme analyzer\n",
        "from konlpy.tag import Kkma, Komoran, Okt, Mecab\n",
        "from konlpy.utils import pprint\n",
        "\n",
        "# import etc\n",
        "from google.colab import files\n",
        "import time\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "# Change run location, 제출시에 제거\n",
        "# %cd /content/drive/My Drive/DeepLearning/PROJECT_AON\n",
        "# Matplotlib set font on NanumBarunGothic\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "# Numpy print set\n",
        "np.set_printoptions(linewidth=200, precision=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DeepLearning/PROJECT_AON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGm7Up9L5Y98"
      },
      "source": [
        "#Grobal Variable\n",
        "*   [Concept Reference](https://reniew.github.io/25/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4l77b8v5aKe"
      },
      "source": [
        "\"\"\"\n",
        "ranking about time spent morpheme analyzing (The fastest is number one.)\n",
        "\n",
        "1. Mecab\n",
        "2. Komoran\n",
        "3. Okt\n",
        "4. Kkma\n",
        "\n",
        "Mecab is faster than Kkma about 30~40 times\n",
        "Mecab is faster than Okt about 10 times\n",
        "Mecab is faster than Komoran about 5 times\n",
        "\"\"\"\n",
        "\n",
        "# Early versions use macab.\n",
        "MECAB = Mecab()\n",
        "\n",
        "# Learning target's name\n",
        "AI_TARGET_NAME = \"대석\"\n",
        "\n",
        "# Output size Or Time_step\n",
        "OOT = 5\n",
        "\n",
        "# Word2vec model\n",
        "CORPUS = Word2VecKeyedVectors(vector_size=OOT)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtyggGY871Bm"
      },
      "source": [
        "# Funtion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm5-VhoeT8Jx"
      },
      "source": [
        "Data Prepare Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8emd9lpUyXR"
      },
      "source": [
        "# Functions that extract reply time (minute)\n",
        "def extract_replytime(content) :\n",
        "    idx_list1 = [i for i, value in enumerate(content) if value == ']']\n",
        "    idx_list2 = [i for i, value in enumerate(content) if value == '[']\n",
        "\n",
        "    end_idx = idx_list1[1]\n",
        "    start_idx = idx_list2[1] + 1\n",
        "\n",
        "    replytime = content[start_idx : end_idx]\n",
        "\n",
        "    if replytime[:2] == \"오전\" :\n",
        "        replytime = (int(replytime[2:replytime.index(\":\")]) * 60) + int(replytime[replytime.index(\":\") + 1 :])\n",
        "    else :\n",
        "        replytime = 60 * 12 + (int(replytime[2:replytime.index(\":\")]) * 60) + int(replytime[replytime.index(\":\") + 1 :])\n",
        "\n",
        "    return replytime\n",
        "\n",
        "# Functions that comparison about reply time\n",
        "def compare_replytime(pre_text, cur_text) :\n",
        "    pre_time = extract_replytime(pre_text)\n",
        "    cur_time = extract_replytime(cur_text)\n",
        "\n",
        "    result = False\n",
        "    if cur_time - pre_time >= 10 : result = True\n",
        "\n",
        "    return result\n",
        "\n",
        "# Functions that extract Data about kakao talk's content\n",
        "def extract_data(X_dataset, y_dataset, talk_list) :\n",
        "    global AI_TARGET_NAME\n",
        "\n",
        "    for talk in talk_list :\n",
        "        tmp_X_respondents = []\n",
        "        tmp_y_respondents = []\n",
        "        for texts in talk.values :\n",
        "            tmp_X_replys = []\n",
        "            tmp_y_replys = []\n",
        "\n",
        "            tmp_X_texts = []\n",
        "            tmp_y_texts = []\n",
        "\n",
        "            before_respondent = \"\"\n",
        "\n",
        "            texts = texts.tolist()\n",
        "            for idx, text in enumerate(texts) : \n",
        "                # Don't extract email and date\n",
        "                if (not \"저장한 날짜\" in text) and (not \"--------------\" in text) and (not \"@\" in text) :\n",
        "                    if not \"]\" in text : \n",
        "                        if before_respondent == AI_TARGET_NAME : tmp_y_texts.append(text)\n",
        "                        else : tmp_X_texts.append(text)\n",
        "\n",
        "                        continue\n",
        "                    else : cur_respondent = text[1:text.index(\"]\")]\n",
        "\n",
        "                    if (\":\" in text) and (before_respondent != \"\") :\n",
        "                        if compare_replytime(texts[idx - 1], text) or cur_respondent != before_respondent:\n",
        "                            if len(tmp_X_texts) != 0 : tmp_X_replys.append(tmp_X_texts)\n",
        "                            if len(tmp_y_texts) != 0 : tmp_y_replys.append(tmp_y_texts)\n",
        "                            tmp_X_texts = []\n",
        "                            tmp_y_texts = []\n",
        "\n",
        "                    if AI_TARGET_NAME in text[1:text.index(\"]\")] :\n",
        "                        ptext = text[(text.rfind(']') + 2) : len(text)]\n",
        "                        if ptext.find(\"http\") == -1 and ptext != \"사진\" and ptext != \"\" : \n",
        "                            before_respondent = AI_TARGET_NAME\n",
        "                            if ptext != '' : tmp_y_texts.append(ptext)\n",
        "                    elif \"]\" in text :\n",
        "                        ptext = text[(text.rfind(']') + 2) : len(text)]\n",
        "                        if ptext.find(\"http\") == -1 and ptext != \"사진\" and ptext != \"\" : \n",
        "                            before_respondent = cur_respondent\n",
        "                            if ptext != '' : tmp_X_texts.append(ptext)\n",
        "\n",
        "                    if idx == len(texts) - 1 :\n",
        "                        if len(tmp_X_texts) != 0 : tmp_X_replys.append(tmp_X_texts)\n",
        "                        if len(tmp_y_texts) != 0 : tmp_y_replys.append(tmp_y_texts)\n",
        "\n",
        "            if len(tmp_X_replys) != 0 : tmp_X_respondents.append(tmp_X_replys)\n",
        "            if len(tmp_y_replys) != 0 : tmp_y_respondents.append(tmp_y_replys)\n",
        "\n",
        "        if len(tmp_X_respondents) != 0 : X_dataset.append(tmp_X_respondents)\n",
        "        if len(tmp_y_respondents) != 0 : y_dataset.append(tmp_y_respondents)\n",
        "\n",
        "# Functions that init reply's data type is list. so, change data type to str by this function\n",
        "def unzip_replys(X_dataset, y_dataset) :\n",
        "    # If don't use list, data type is str. this is caused by need just one word on word2vec\n",
        "    for idx, respondent in enumerate(X_dataset) : \n",
        "        for i, reply in enumerate(respondent) :\n",
        "            X_dataset[idx][i] = X_dataset[idx][i][0][0].split()\n",
        "\n",
        "    for idx, respondent in enumerate(y_dataset) : \n",
        "        for i, reply in enumerate(respondent) :\n",
        "            y_dataset[idx][i] = y_dataset[idx][i][0][0].split()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smqf-vLlU03k"
      },
      "source": [
        "Data Pre-processing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMp3NxIaU1Cp"
      },
      "source": [
        "# Functions that auto calibrate spacing functions\n",
        "def auto_spacing(X_dataset, y_dataset) :\n",
        "    calibrate_spcaing(X_dataset)\n",
        "    calibrate_spcaing(y_dataset)\n",
        "\n",
        "def calibrate_spcaing(context_dataset) :\n",
        "    global MECAB\n",
        "\n",
        "    for order, respondent in enumerate(context_dataset) :\n",
        "        for idx, texts in enumerate(respondent) :\n",
        "            for repairIdx, text in enumerate(texts) :\n",
        "                analyzedRes = MECAB.pos(text)\n",
        "                for mecabR in analyzedRes :\n",
        "                    # \"MAG\" == Adverb\n",
        "                    if mecabR[1] == \"MAG\" :\n",
        "                        try :\n",
        "                            startIdx = text.index(mecabR[0])\n",
        "                            if len(mecabR[0]) == 1 :\n",
        "                                if text[startIdx + 1] != \" \" and text[startIdx + 1].isalnum() : \n",
        "                                    if text[startIdx + 2] != \" \" :\n",
        "                                        text = text[:startIdx] + text[startIdx] + \" \" + text[startIdx + 1 :]\n",
        "                                        context_dataset[order][idx][repairIdx] = text\n",
        "                            else : \n",
        "                                if text[startIdx + len(mecabR[0])] != \" \" and text[startIdx + len(mecabR[0])].isalnum() : \n",
        "                                    if text[startIdx + len(mecabR[0]) + 1] != \" \" :\n",
        "                                        text = text[:startIdx] + text[startIdx : startIdx + len(mecabR[0])] + \" \" + text[startIdx + len(mecabR[0]) :]\n",
        "                                        context_dataset[order][idx][repairIdx] = text\n",
        "                        except IndexError :\n",
        "                            continue\n",
        "\n",
        "# Functions that delete stopword in sentence\n",
        "def stopword_filtering(X_dataset, y_dataset) :\n",
        "    delete_stopword(X_dataset)\n",
        "    delete_stopword(y_dataset)\n",
        "\n",
        "def delete_stopword(word_dataset) :\n",
        "    global MECAB\n",
        "\n",
        "    stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','하다']\n",
        "    for order, respondent in enumerate(word_dataset) :\n",
        "        for idx, reply in enumerate(respondent) :\n",
        "            for i, text in enumerate(reply) :\n",
        "                tokenized_data = MECAB.morphs(text)\n",
        "                tokenized_data = [word for word in tokenized_data if not word in stop_words]\n",
        "                result_text = ''.join(tokenized_data)\n",
        "                if result_text != '' : word_dataset[order][idx][i] = result_text\n",
        "\n",
        "# Functions that divide X, y dataset in learning set\n",
        "def combine_dataset(X_dataset, y_dataset) :\n",
        "    global OOT\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    for idx in range(0, len(X_dataset)) :\n",
        "\n",
        "        if len(X_dataset[idx]) > len(y_dataset[idx]) : X_dataset[idx] = X_dataset[idx][1 : len(y_dataset[idx]) + 1]\n",
        "        elif len(y_dataset[idx]) > len(X_dataset[idx]) : y_dataset[idx] = y_dataset[idx][1 : len(X_dataset[idx]) + 1]\n",
        "\n",
        "        if idx == 0 :\n",
        "            X.append(X_dataset[idx].reshape(X_dataset[idx].shape[0], 1, 1))\n",
        "            y.append(y_dataset[idx].reshape(y_dataset[idx].shape[0], 1, 1))\n",
        "        elif idx == 1 :\n",
        "            X = np.r_[X[0], X_dataset[idx].reshape(X_dataset[idx].shape[0], 1, 1)]\n",
        "            y = np.r_[y[0], y_dataset[idx].reshape(y_dataset[idx].shape[0], 1, 1)]\n",
        "        else :\n",
        "            X = np.r_[X, X_dataset[idx].reshape(X_dataset[idx].shape[0], 1, 1)]\n",
        "            y = np.r_[y, y_dataset[idx].reshape(y_dataset[idx].shape[0], 1, 1)]\n",
        "\n",
        "    # Set the total number of datasets to be a multiple of 10\n",
        "    if len(X) % 10 != 0 : X = X[0 : (len(X) - (len(X) % 10 ))]\n",
        "    if len(y) % 10 != 0 : y = y[0 : (len(y) - (len(y) % 10 ))]\n",
        "\n",
        "    # Reshape timestep and vector_length\n",
        "    return X.reshape(int(X.shape[0]/OOT), OOT, 1), y.reshape(int(y.shape[0]/OOT), OOT, 1)\n",
        "\n",
        "# Functions that factorization for reshaping's variable (just one)\n",
        "def factorization(x) :\n",
        "    d = 2 \n",
        "    \n",
        "    while d <= x : \n",
        "        if x % d == 0 : break\n",
        "        else : d = d + 1\n",
        "    \n",
        "    return d\n",
        "\n",
        "def set_output_size(dataset) :\n",
        "    for respondent in dataset :\n",
        "        print(len(respondent))\n",
        "\n",
        "# 빈도수 너무 높거나 낮은건 제외하는 메서드 추가 고려 (데이터 학습 제대로 안 되면)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lglCQxR0WGhE"
      },
      "source": [
        "Word2Vec Functions (Distributed Representation)\n",
        "*   [Word2Vec Reference 1](https://ebbnflow.tistory.com/153)\n",
        "*   [Word2Vec Reference 2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)\n",
        "\n",
        "\n",
        "*   [gensim Word2VecKeyedVectors, add](https://github.com/RaRe-Technologies/gensim/issues/2268)\n",
        "\n",
        "\n",
        "*   [PCA(sklearn) Reference](https://m.blog.naver.com/tjdrud1323/221720259834)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aaczn0GQ71N4"
      },
      "source": [
        "# Functions that draw a two-dimensional graph by entering the words, values of the two-dimensional X-axis, and values of the Y-axis.\n",
        "def plot_2d_graph(vocabs, xs, ys):\n",
        "    plt.figure(figsize=(8 ,6))\n",
        "    plt.scatter(xs, ys, marker = 'o')\n",
        "    for i, v in enumerate(vocabs):\n",
        "        plt.annotate(v, xy=(xs[i], ys[i]))\n",
        "\n",
        "# Functions that conversioning dataset to word2vec format\n",
        "def dataset_to_word2vec(X_dataset, y_dataset) :\n",
        "    return word2vec(X_dataset, True), word2vec(y_dataset, False)\n",
        "\n",
        "def word2vec(word_dataset, isXdataset) :\n",
        "    global CORPUS, OOT\n",
        "\n",
        "    result = []\n",
        "    for idx, respondent in enumerate(word_dataset) :\n",
        "        # Init words and vectors\n",
        "        w2v = Word2Vec(respondent, size=OOT, window=3, min_count=1, workers=6, sg=1)\n",
        "\n",
        "        # Set word vectors\n",
        "        if isXdataset : CORPUS.add(entities=list(w2v.wv.vocab.keys()), weights=w2v.wv.vectors, replace=False)\n",
        "        vocabs = CORPUS.vocab.keys()\n",
        "        word_vector_list = [CORPUS[v] for v in vocabs]\n",
        "\n",
        "        # Confirm word similarity\n",
        "        # if \"경호\" in vocabs : print(word_vectors.most_similar(\"경호\"))\n",
        "        # else : print(word_vectors.most_similar(\"대석\"))\n",
        "        \n",
        "        pca = PCA(n_components=OOT)\n",
        "        xys = pca.fit_transform(word_vector_list)\n",
        "        xs = xys[:,0]\n",
        "        ys = xys[:,1]\n",
        "\n",
        "        # Normalization\n",
        "        scaler = MinMaxScaler()\n",
        "        scaler.fit(xys)\n",
        "        xys = scaler.transform(xys)\n",
        "\n",
        "        # Change corpus's values to normalized data\n",
        "        for idx, key in enumerate(vocabs) : CORPUS[[key]][0] = xys[idx]\n",
        "\n",
        "        # plot_2d_graph(vocabs, xs, ys)\n",
        "        result.append(xys.reshape(-1))\n",
        "\n",
        "    return np.array(result)\n",
        "\n",
        "def word2vec_talk(talk) :\n",
        "    global OOT\n",
        "    \n",
        "    w2v = Word2Vec(talk, size=OOT, window=3, min_count=1, workers=6, sg=1)\n",
        "\n",
        "    # Set word vectors\n",
        "    word_vectors = w2v.wv\n",
        "    vocabs = word_vectors.vocab.keys()\n",
        "    word_vector_list = [word_vectors[v] for v in vocabs]\n",
        "    \n",
        "    word_vector_list = np.asarray(word_vector_list)\n",
        "\n",
        "    # Confirm word similarity\n",
        "    # if \"경호\" in vocabs : print(word_vectors.most_similar(\"경호\"))\n",
        "    # else : print(word_vectors.most_similar(\"대석\"))\n",
        "\n",
        "    return word_vector_list.reshape(-1)\n",
        "\n",
        "# Functions that conversioning data that formed vector to word\n",
        "def vec2word(vec, isreshape=False, isvec=True, beforeWords=[]) :\n",
        "    global MECAB, CORPUS\n",
        "\n",
        "    sentence = \"\"\n",
        "    if isvec :\n",
        "        if isreshape : sentence = sentence + CORPUS.most_similar(positive=[vec.reshape(OOT,)])[0][0]\n",
        "        else : sentence = sentence + CORPUS.most_similar(positive=[vec])[0][0]\n",
        "    else :\n",
        "        word = CORPUS.most_similar(vec)[0][0]\n",
        "\n",
        "        if not word in beforeWords : sentence = sentence + word\n",
        "        else :\n",
        "            for similar in CORPUS.most_similar(vec) :\n",
        "                if not similar[0] in beforeWords :\n",
        "                    sentence = sentence + similar[0]\n",
        "                    break\n",
        "\n",
        "    stop_poses = ['EC', 'EF', 'SF', 'SP', 'SS', 'SO']\n",
        "    tokenized_data = MECAB.pos(sentence)\n",
        "    for pos in stop_poses :\n",
        "        if pos in tokenized_data[len(tokenized_data) - 1][1] : return sentence  \n",
        "\n",
        "    if not sentence in beforeWords : beforeWords.append(sentence)\n",
        "    sentence = sentence + ' ' + vec2word(sentence, isreshape=isreshape, isvec=False, beforeWords=beforeWords)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzZv5jsvHH-o"
      },
      "source": [
        "Model Learning Functions\n",
        "*   [Keras loss function Reference](https://keras.io/api/losses/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOQuvy5EHIGL"
      },
      "source": [
        "# Functions that make up the model\n",
        "def modeling_model() :\n",
        "    global model\n",
        "\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same', input_shape=(OOT, 1)))\n",
        "    model.add(MaxPooling1D(pool_size=3, padding='same'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "    model.add(MaxPooling1D(pool_size=3, padding='same'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "    model.add(MaxPooling1D(pool_size=3, padding='same'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "    model.add(MaxPooling1D(pool_size=3, padding='same'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "    model.add(MaxPooling1D(pool_size=3, padding='same'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation=\"sigmoid\")) # Performance improves once it passes through layers that have been amplified datas\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(OOT,activation=\"softmax\")) # output data == n( == y_dataset.shape[1]) things\n",
        "    model.compile(\n",
        "        loss=losses.MeanSquaredError(),\n",
        "        optimizer=Adam(learning_rate=0.0001), # pram ex. learning_rate=0.0001\n",
        "        metrics=[metrics.MeanSquaredError()]\n",
        "    )\n",
        "\n",
        "# Function to learn the configured model with the training datas\n",
        "def training_model(X_train, y_train, X_val, y_val) :\n",
        "    global model\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "          validation_data = (X_val, y_val),\n",
        "          batch_size = 32,\n",
        "          epochs = 128,\n",
        "          verbose = 1, # 0 = silent, 1 = progress bar,  2 = one line per epoch.\n",
        "          )\n",
        "    \n",
        "    return history\n",
        "    \n",
        "# Function to evaluate the learned model\n",
        "def evaluating_model(X_test, y_test, history) :\n",
        "    global model\n",
        "\n",
        "    # loss and acc graph (train and val)\n",
        "    history_df = pd.DataFrame(history.history)\n",
        "    history_df[[\"loss\", \"val_loss\"]].plot()\n",
        "\n",
        "    # Acc and Loss about real data\n",
        "    learning_lost, learning_err = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print(\"Learning error % :\", learning_err * 100)\n",
        "    print(\"Learning loss % :\", learning_lost * 100)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxjmmKaVlO9p"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea9DIOdiQ_0o"
      },
      "source": [
        "Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcHWaWjaREpT"
      },
      "source": [
        "# uploaded_files = files.upload()\n",
        "\n",
        "file_list = os.listdir('./')\n",
        "fs = [f for f in file_list if f.endswith('.txt')]\n",
        "\n",
        "talk_list = []\n",
        "for f in fs :\n",
        "    \"\"\" \n",
        "    ERROR 3. ParserError: Error tokenizing data. C error \n",
        "    - Solution: add code in read_csv = , sep='\\t'\n",
        "    \"\"\"\n",
        "    talk_list.append(pd.read_csv(f, sep='\\t'))\n",
        "\n",
        "# Init Dataset\n",
        "X_dataset = []\n",
        "y_dataset = []\n",
        "\n",
        "# Data extraction\n",
        "extract_data(X_dataset, y_dataset, talk_list)\n",
        "\n",
        "# Early version is used y_list[][0] and x_list[][0] (1 word) by learning model\n",
        "unzip_replys(X_dataset, y_dataset)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG9R5wKTSNwi"
      },
      "source": [
        "Pre-processing Data\n",
        "*  [Dataset Classification Reference 1](https://ganghee-lee.tistory.com/38)\n",
        "*  [Dataset Classification Reference 2](https://ysyblog.tistory.com/69)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HENnALQjSN3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1802f638-c885-486f-93d3-e0d943ab6041"
      },
      "source": [
        "# Space Modification\n",
        "auto_spacing(X_dataset, y_dataset)\n",
        "\n",
        "# Stopword deleted\n",
        "stopword_filtering(X_dataset, y_dataset)\n",
        "\n",
        "# Data type change on np.ndarray\n",
        "X_dataset = np.asarray(X_dataset).astype(object)\n",
        "y_dataset = np.asarray(y_dataset).astype(object)\n",
        "\n",
        "# Word2Vec on dataset\n",
        "X_dataset, y_dataset = dataset_to_word2vec(X_dataset, y_dataset)\n",
        "\n",
        "# Set learning dataset\n",
        "X_dataset, y_dataset = combine_dataset(X_dataset, y_dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5KUvpUqJjwe"
      },
      "source": [
        "Model Training\n",
        "*   [NLP Reference](https://towardsdatascience.com/natural-language-processing-a-crash-course-73d7a07c240c)\n",
        "*   [Issue: Model predictional result is always same](https://github.com/keras-team/keras/issues/6447)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67l_qIoJJjVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57867b73-e563-4ac5-8d5d-7fd21ab7c9f4"
      },
      "source": [
        "# Data division (Train : Test = 8 : 2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset,\n",
        "                                                    test_size = 0.2)\n",
        "print(\"########## Train + Validation (X,) (y,) / Test (X,) (y,) ##########\")\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "# Data division (Train : Validation = 8 : 2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                    test_size = 0.2)\n",
        "print(\"########## Train (X,) (y,) / Validation (X,) (y,) ##########\")\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
        "\n",
        "print('\\n')\n",
        "if os.path.isfile('Aengmu.h5') : \n",
        "    # Load model\n",
        "    print('#################### Model Load... ####################')\n",
        "    model = tf.keras.models.load_model('Aengmu.h5')\n",
        "else :\n",
        "    print('#################### Init Model... ####################')\n",
        "    # Laerning model\n",
        "    model = Sequential()\n",
        "    # Modeling\n",
        "    modeling_model()\n",
        "    \n",
        "# Training\n",
        "history = training_model(X_train, y_train, X_val, y_val)\n",
        "# Evaluating\n",
        "evaluating_model(X_test, y_test, history)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Train + Validation (X,) (y,) / Test (X,) (y,) ##########\n",
            "(16196, 5, 1) (16196, 5, 1) (4050, 5, 1) (4050, 5, 1)\n",
            "########## Train (X,) (y,) / Validation (X,) (y,) ##########\n",
            "(12956, 5, 1) (12956, 5, 1) (3240, 5, 1) (3240, 5, 1)\n",
            "\n",
            "\n",
            "#################### Init Model... ####################\n",
            "Epoch 1/128\n",
            "405/405 [==============================] - 4s 7ms/step - loss: 0.1158 - mean_squared_error: 0.1158 - val_loss: 0.1099 - val_mean_squared_error: 0.1099\n",
            "Epoch 2/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.1092 - mean_squared_error: 0.1092 - val_loss: 0.1076 - val_mean_squared_error: 0.1076\n",
            "Epoch 3/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.1048 - mean_squared_error: 0.1048 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 4/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0997 - mean_squared_error: 0.0997 - val_loss: 0.0997 - val_mean_squared_error: 0.0997\n",
            "Epoch 5/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0979 - mean_squared_error: 0.0979 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
            "Epoch 6/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0973 - mean_squared_error: 0.0973 - val_loss: 0.0989 - val_mean_squared_error: 0.0989\n",
            "Epoch 7/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0970 - mean_squared_error: 0.0970 - val_loss: 0.0986 - val_mean_squared_error: 0.0986\n",
            "Epoch 8/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0967 - mean_squared_error: 0.0967 - val_loss: 0.0984 - val_mean_squared_error: 0.0984\n",
            "Epoch 9/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0964 - mean_squared_error: 0.0964 - val_loss: 0.0982 - val_mean_squared_error: 0.0982\n",
            "Epoch 10/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0963 - mean_squared_error: 0.0963 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n",
            "Epoch 11/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0961 - mean_squared_error: 0.0961 - val_loss: 0.0980 - val_mean_squared_error: 0.0980\n",
            "Epoch 12/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0960 - mean_squared_error: 0.0960 - val_loss: 0.0979 - val_mean_squared_error: 0.0979\n",
            "Epoch 13/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0959 - mean_squared_error: 0.0959 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
            "Epoch 14/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0959 - mean_squared_error: 0.0959 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
            "Epoch 15/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0958 - mean_squared_error: 0.0958 - val_loss: 0.0977 - val_mean_squared_error: 0.0977\n",
            "Epoch 16/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0957 - mean_squared_error: 0.0957 - val_loss: 0.0976 - val_mean_squared_error: 0.0976\n",
            "Epoch 17/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0957 - mean_squared_error: 0.0957 - val_loss: 0.0976 - val_mean_squared_error: 0.0976\n",
            "Epoch 18/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0956 - mean_squared_error: 0.0956 - val_loss: 0.0976 - val_mean_squared_error: 0.0976\n",
            "Epoch 19/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0956 - mean_squared_error: 0.0956 - val_loss: 0.0975 - val_mean_squared_error: 0.0975\n",
            "Epoch 20/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0955 - mean_squared_error: 0.0955 - val_loss: 0.0974 - val_mean_squared_error: 0.0974\n",
            "Epoch 21/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0955 - mean_squared_error: 0.0955 - val_loss: 0.0974 - val_mean_squared_error: 0.0974\n",
            "Epoch 22/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0954 - mean_squared_error: 0.0954 - val_loss: 0.0973 - val_mean_squared_error: 0.0973\n",
            "Epoch 23/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0953 - mean_squared_error: 0.0953 - val_loss: 0.0973 - val_mean_squared_error: 0.0973\n",
            "Epoch 24/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0953 - mean_squared_error: 0.0953 - val_loss: 0.0972 - val_mean_squared_error: 0.0972\n",
            "Epoch 25/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0952 - mean_squared_error: 0.0952 - val_loss: 0.0971 - val_mean_squared_error: 0.0971\n",
            "Epoch 26/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0952 - mean_squared_error: 0.0952 - val_loss: 0.0971 - val_mean_squared_error: 0.0971\n",
            "Epoch 27/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0951 - mean_squared_error: 0.0951 - val_loss: 0.0970 - val_mean_squared_error: 0.0970\n",
            "Epoch 28/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0951 - mean_squared_error: 0.0951 - val_loss: 0.0970 - val_mean_squared_error: 0.0970\n",
            "Epoch 29/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0950 - mean_squared_error: 0.0950 - val_loss: 0.0969 - val_mean_squared_error: 0.0969\n",
            "Epoch 30/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0950 - mean_squared_error: 0.0950 - val_loss: 0.0968 - val_mean_squared_error: 0.0968\n",
            "Epoch 31/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0949 - mean_squared_error: 0.0949 - val_loss: 0.0968 - val_mean_squared_error: 0.0968\n",
            "Epoch 32/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0949 - mean_squared_error: 0.0949 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
            "Epoch 33/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0948 - mean_squared_error: 0.0948 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
            "Epoch 34/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0948 - mean_squared_error: 0.0948 - val_loss: 0.0966 - val_mean_squared_error: 0.0966\n",
            "Epoch 35/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0947 - mean_squared_error: 0.0947 - val_loss: 0.0966 - val_mean_squared_error: 0.0966\n",
            "Epoch 36/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0947 - mean_squared_error: 0.0947 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
            "Epoch 37/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0946 - mean_squared_error: 0.0946 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
            "Epoch 38/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0946 - mean_squared_error: 0.0946 - val_loss: 0.0964 - val_mean_squared_error: 0.0964\n",
            "Epoch 39/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0945 - mean_squared_error: 0.0945 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
            "Epoch 40/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0945 - mean_squared_error: 0.0945 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
            "Epoch 41/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0944 - mean_squared_error: 0.0944 - val_loss: 0.0961 - val_mean_squared_error: 0.0961\n",
            "Epoch 42/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0943 - mean_squared_error: 0.0943 - val_loss: 0.0961 - val_mean_squared_error: 0.0961\n",
            "Epoch 43/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0942 - mean_squared_error: 0.0942 - val_loss: 0.0958 - val_mean_squared_error: 0.0958\n",
            "Epoch 44/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0939 - mean_squared_error: 0.0939 - val_loss: 0.0953 - val_mean_squared_error: 0.0953\n",
            "Epoch 45/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0932 - mean_squared_error: 0.0932 - val_loss: 0.0943 - val_mean_squared_error: 0.0943\n",
            "Epoch 46/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0923 - mean_squared_error: 0.0923 - val_loss: 0.0937 - val_mean_squared_error: 0.0937\n",
            "Epoch 47/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0919 - mean_squared_error: 0.0919 - val_loss: 0.0934 - val_mean_squared_error: 0.0934\n",
            "Epoch 48/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0917 - mean_squared_error: 0.0917 - val_loss: 0.0932 - val_mean_squared_error: 0.0932\n",
            "Epoch 49/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0915 - mean_squared_error: 0.0915 - val_loss: 0.0931 - val_mean_squared_error: 0.0931\n",
            "Epoch 50/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0913 - mean_squared_error: 0.0913 - val_loss: 0.0930 - val_mean_squared_error: 0.0930\n",
            "Epoch 51/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0913 - mean_squared_error: 0.0913 - val_loss: 0.0930 - val_mean_squared_error: 0.0930\n",
            "Epoch 52/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.0929 - val_mean_squared_error: 0.0929\n",
            "Epoch 53/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.0929 - val_mean_squared_error: 0.0929\n",
            "Epoch 54/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0929 - val_mean_squared_error: 0.0929\n",
            "Epoch 55/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0929 - val_mean_squared_error: 0.0929\n",
            "Epoch 56/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 57/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 58/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 59/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 60/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 61/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 62/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 63/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 64/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 65/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 66/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 67/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 68/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 69/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
            "Epoch 70/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 71/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 72/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 73/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 74/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 75/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 76/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 77/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 78/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 79/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 80/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 81/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 82/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 83/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 84/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 85/128\n",
            "405/405 [==============================] - 3s 6ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 86/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 87/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 88/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 89/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 90/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 91/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 92/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 93/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 94/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 95/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 96/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 97/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 98/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 99/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 100/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 101/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 102/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 103/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 104/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 105/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 106/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 107/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 108/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 109/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 110/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 111/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 112/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 113/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 114/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 115/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 116/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 117/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 118/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 119/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 120/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 121/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 122/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 123/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 124/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 125/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 126/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 127/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "Epoch 128/128\n",
            "405/405 [==============================] - 3s 7ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
            "127/127 - 0s - loss: 0.0914 - mean_squared_error: 0.0914\n",
            "Learning error % : 9.143729507923126\n",
            "Learning loss % : 9.143729507923126\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_10 (Conv1D)           (None, 5, 64)             256       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 2, 64)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 2, 64)             12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 1, 64)             12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 1, 64)             12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 1, 64)             12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 58,629\n",
            "Trainable params: 58,629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA4mqS5DTpn5"
      },
      "source": [
        "Prediction (Talk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk3zCKMclQz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825e7677-fd54-4ac2-ae3a-4774260d1849"
      },
      "source": [
        "while True :\n",
        "    try :\n",
        "        talk = input(\"앵무에게 보낼 카톡: \")\n",
        "\n",
        "        if talk == \"\" : \n",
        "            print(\"대화 종료\")\n",
        "            break\n",
        "\n",
        "        talk_vec = word2vec_talk(list(talk))\n",
        "        talk_vec = talk_vec.reshape(int(talk_vec.shape[0]/OOT), OOT, 1)\n",
        "        Aengmu = model.predict(talk_vec)\n",
        "\n",
        "        print(vec2word(Aengmu[len(Aengmu) - 1]))\n",
        "        print('\\n')\n",
        "\n",
        "    except ValueError :\n",
        "        print(\"ERROR, code 00001\")\n",
        "        break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "앵무에게 보낼 카톡: 안녕\n",
            "전씨랑 500일 바라지 ㅋㅋㅋㅋ십ㄹ 그렇다는데\n",
            "앵무에게 보낼 카톡: ?????????\n",
            "야ㅔ돼 청량산 하나야 해결했누\n",
            "앵무에게 보낼 카톡: 뭐야\n",
            "무쁘지 애매할스도 조져\n",
            "앵무에게 보낼 카톡: 됐다\n",
            "전씨랑 머함?\n",
            "앵무에게 보낼 카톡: 오오오\n",
            "애매할스도 조져\n",
            "앵무에게 보낼 카톡: 됐어!!!!!!!!!!!!!!!!\n",
            "9시반쯤 시작함 갈수잇을듯 수2 서비스 아픔라하더라고\n",
            "앵무에게 보낼 카톡: 네이스~\n",
            "수1 자유교양면 순전파 모르거나\n",
            "앵무에게 보낼 카톡: 됐다구 줴엔장\n",
            "모르거나\n",
            "앵무에게 보낼 카톡: \n",
            "대화 종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0_MpEIFjCOK"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JpataRYhQAr"
      },
      "source": [
        "#model.save('Aengmu.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}