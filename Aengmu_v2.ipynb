{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aengmu_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcAoYmakklBgcA9dDSflpa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/NLP-Aengmu/blob/main/Aengmu_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtLYgO_OxLaU"
      },
      "source": [
        "# [ERROR 4] Korean(Hangul) breaking phenomenon Solution on Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce18aOPbxLkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9cf9f91-8bd3-4512-9a42-4f6131baa951"
      },
      "source": [
        "\"\"\" \n",
        "ERROR 4. plot \"Korean\" breaking phenomenon\n",
        "- Solution: Installing(↓) and setting(plt.rc('font', family='NanumBarunGothic')) Nanum font, after runtime restart\n",
        "\"\"\"\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20170925-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 4 dirs\n",
            "/usr/share/fonts/truetype/dejavu: caching, new cache contents: 22 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96hYYUFzcaxY"
      },
      "source": [
        "# Google Drive Local Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHqDHk2ucc7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838d42be-c00e-4e0e-b1dd-bfd89122023f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgHeq1Zcb7M2"
      },
      "source": [
        "# Install Morpheme analyzer\n",
        "*   [Reference](https://soohee410.github.io/compare_tagger)\n",
        "*   [Install](https://sanghyu.tistory.com/170)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtYcWqVsb5Xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c520927-c248-4d19-ce41-b6bff2934ee3"
      },
      "source": [
        "# okt, komoran, kkma\n",
        "# install konlpy (okt, komoran, kkma)\n",
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy\n",
        "\n",
        "# mecab (take a long time)\n",
        "# set env\n",
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# install konlpy (mecab)\n",
        "%%bash\n",
        "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "pip3 install /tmp/mecab-python-0.996"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "openjdk-8-jdk is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1) (3.7.4.3)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n",
            "Processing /tmp/mecab-python-0.996\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py): started\n",
            "  Building wheel for mecab-python (setup.py): finished with status 'done'\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141812 sha256=5bcdc05708b02c5753344c2d705dbf7012cd7376446d1d5c08851879ff922261\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "  Attempting uninstall: mecab-python\n",
            "    Found existing installation: mecab-python 0.996-ko-0.9.2\n",
            "    Uninstalling mecab-python-0.996-ko-0.9.2:\n",
            "      Successfully uninstalled mecab-python-0.996-ko-0.9.2\n",
            "    Running setup.py install for mecab-python: started\n",
            "    Running setup.py install for mecab-python: finished with status 'done'\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 8: fg: no job control\n",
            "bash: line 11: fg: no job control\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\n",
            "  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GobPxVERuegZ"
      },
      "source": [
        "# Error Solution\n",
        "\n",
        "1. TypeError: startJVM() got an unexpected keyword argument 'convertStrings' [(JVM)](https://gyulogs.tistory.com/130)\n",
        "2. NameError: name 'Tagger' is not defined [(Mecab)](https://sosomemo.tistory.com/31)\n",
        "3. ParserError: Error tokenizing data. C error [(Pandas)](https://mskim8717.tistory.com/82)\n",
        "4. plot \"Korean\" breaking phenomenon on Colab [(Matplotlib)](https://teddylee777.github.io/colab/colab-korean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpM2dDEuuesD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e590cd52-b1c3-46c9-b5b7-5fdf20260b67"
      },
      "source": [
        "\"\"\" \n",
        "ERROR 1. TypeError: startJVM() got an unexpected keyword argument 'convertStrings'\n",
        "- Solution: /usr/local/lib/python3.7/dist-packages/konlpy/jvm.py, 67 line (convertStrings=True) comments processing and save jvm.py before import pakage\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" \n",
        "ERROR 2. NameError: name 'Tagger' is not defined \n",
        "- Solution: Execute mecab.sh script (under code excute)\n",
        "\"\"\"\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "openjdk-8-jdk is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1-py3 in /usr/local/lib/python3.7/dist-packages (0.5.5.4)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu59D-1sc93c"
      },
      "source": [
        "# Import\n",
        "*   [KoNLPy Reperence](https://konlpy-ko.readthedocs.io/ko/v0.4.3/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRaXnlVOWpot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e037fb73-32ae-4c17-c089-f1f03d8412de"
      },
      "source": [
        "# import for MechineLearning\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import metrics, losses, callbacks\n",
        "from tensorflow.keras.optimizers import Adam, Adagrad, SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
        "\n",
        "# import Morpheme analyzer\n",
        "from konlpy.tag import Kkma, Komoran, Okt, Mecab\n",
        "from konlpy.utils import pprint\n",
        "\n",
        "# import etc\n",
        "from google.colab import files\n",
        "import time\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "# Change run location, 제출시에 제거\n",
        "%cd /content/drive/My Drive/DeepLearning/PROJECT_AON\n",
        "# Matplotlib set font on NanumBarunGothic\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "# Numpy print set\n",
        "np.set_printoptions(linewidth=200, precision=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DeepLearning/PROJECT_AON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGm7Up9L5Y98"
      },
      "source": [
        "#Grobal Variable\n",
        "*   [Concept Reference](https://reniew.github.io/25/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4l77b8v5aKe"
      },
      "source": [
        "\"\"\"\n",
        "ranking about time spent morpheme analyzing (The fastest is number one.)\n",
        "\n",
        "1. Mecab\n",
        "2. Komoran\n",
        "3. Okt\n",
        "4. Kkma\n",
        "\n",
        "Mecab is faster than Kkma about 30~40 times\n",
        "Mecab is faster than Okt about 10 times\n",
        "Mecab is faster than Komoran about 5 times\n",
        "\"\"\"\n",
        "\n",
        "# Early versions use macab.\n",
        "MECAB = Mecab()\n",
        "\n",
        "# Learning target's name\n",
        "AI_TARGET_NAME = \"대석\"\n",
        "\n",
        "# Output size Or Time_step\n",
        "OOT = 5\n",
        "\n",
        "# Word2vec model\n",
        "CORPUS = Word2VecKeyedVectors(vector_size=OOT)\n",
        "\n",
        "# Dataset number\n",
        "DN = 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtyggGY871Bm"
      },
      "source": [
        "# Funtion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm5-VhoeT8Jx"
      },
      "source": [
        "Data Prepare Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8emd9lpUyXR"
      },
      "source": [
        "# Functions that extract reply time (minute)\n",
        "def extract_replytime(content) :\n",
        "    idx_list1 = [i for i, value in enumerate(content) if value == ']']\n",
        "    idx_list2 = [i for i, value in enumerate(content) if value == '[']\n",
        "\n",
        "    end_idx = idx_list1[1]\n",
        "    start_idx = idx_list2[1] + 1\n",
        "\n",
        "    replytime = content[start_idx : end_idx]\n",
        "\n",
        "    if replytime[:2] == \"오전\" :\n",
        "        replytime = (int(replytime[2:replytime.index(\":\")]) * 60) + int(replytime[replytime.index(\":\") + 1 :])\n",
        "    else :\n",
        "        replytime = 60 * 12 + (int(replytime[2:replytime.index(\":\")]) * 60) + int(replytime[replytime.index(\":\") + 1 :])\n",
        "\n",
        "    return replytime\n",
        "\n",
        "# Functions that comparison about reply time\n",
        "def compare_replytime(pre_text, cur_text) :\n",
        "    pre_time = extract_replytime(pre_text)\n",
        "    cur_time = extract_replytime(cur_text)\n",
        "\n",
        "    result = False\n",
        "    if cur_time - pre_time >= 10 : result = True\n",
        "\n",
        "    return result\n",
        "\n",
        "# Functions that extract Data about kakao talk's content\n",
        "def extract_data(X_dataset, y_dataset, talk_list) :\n",
        "    global AI_TARGET_NAME\n",
        "\n",
        "    for talk in talk_list :\n",
        "        tmp_X_respondents = []\n",
        "        tmp_y_respondents = []\n",
        "        for texts in talk.values :\n",
        "            tmp_X_replys = []\n",
        "            tmp_y_replys = []\n",
        "\n",
        "            tmp_X_texts = []\n",
        "            tmp_y_texts = []\n",
        "\n",
        "            before_respondent = \"\"\n",
        "\n",
        "            texts = texts.tolist()\n",
        "            for idx, text in enumerate(texts) : \n",
        "                # Don't extract email and date\n",
        "                if (not \"저장한 날짜\" in text) and (not \"--------------\" in text) and (not \"@\" in text) :\n",
        "                    if not \"]\" in text : \n",
        "                        if before_respondent == AI_TARGET_NAME : tmp_y_texts.append(text)\n",
        "                        else : tmp_X_texts.append(text)\n",
        "\n",
        "                        continue\n",
        "                    else : cur_respondent = text[1:text.index(\"]\")]\n",
        "\n",
        "                    if (\":\" in text) and (before_respondent != \"\") :\n",
        "                        if compare_replytime(texts[idx - 1], text) or cur_respondent != before_respondent:\n",
        "                            if len(tmp_X_texts) != 0 : tmp_X_replys.append(tmp_X_texts)\n",
        "                            if len(tmp_y_texts) != 0 : tmp_y_replys.append(tmp_y_texts)\n",
        "                            tmp_X_texts = []\n",
        "                            tmp_y_texts = []\n",
        "\n",
        "                    if AI_TARGET_NAME in text[1:text.index(\"]\")] :\n",
        "                        ptext = text[(text.rfind(']') + 2) : len(text)]\n",
        "                        if ptext.find(\"http\") == -1 and ptext != \"사진\" and ptext != \"\" : \n",
        "                            before_respondent = AI_TARGET_NAME\n",
        "                            if ptext != '' : tmp_y_texts.append(ptext)\n",
        "                    elif \"]\" in text :\n",
        "                        ptext = text[(text.rfind(']') + 2) : len(text)]\n",
        "                        if ptext.find(\"http\") == -1 and ptext != \"사진\" and ptext != \"\" : \n",
        "                            before_respondent = cur_respondent\n",
        "                            if ptext != '' : tmp_X_texts.append(ptext)\n",
        "\n",
        "                    if idx == len(texts) - 1 :\n",
        "                        if len(tmp_X_texts) != 0 : tmp_X_replys.append(tmp_X_texts)\n",
        "                        if len(tmp_y_texts) != 0 : tmp_y_replys.append(tmp_y_texts)\n",
        "\n",
        "            if len(tmp_X_replys) != 0 : tmp_X_respondents.append(tmp_X_replys)\n",
        "            if len(tmp_y_replys) != 0 : tmp_y_respondents.append(tmp_y_replys)\n",
        "\n",
        "        if len(tmp_X_respondents) != 0 : X_dataset.append(tmp_X_respondents)\n",
        "        if len(tmp_y_respondents) != 0 : y_dataset.append(tmp_y_respondents)\n",
        "\n",
        "# Functions that init reply's data type is list. so, change data type to str by this function\n",
        "def unzip_replys(X_dataset, y_dataset) :\n",
        "    # If don't use list, data type is str. this is caused by need just one word on word2vec\n",
        "    for idx, respondent in enumerate(X_dataset) : \n",
        "        for i, reply in enumerate(respondent) :\n",
        "            X_dataset[idx][i] = X_dataset[idx][i][0][0].split()\n",
        "\n",
        "    for idx, respondent in enumerate(y_dataset) : \n",
        "        for i, reply in enumerate(respondent) :\n",
        "            y_dataset[idx][i] = y_dataset[idx][i][0][0].split()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smqf-vLlU03k"
      },
      "source": [
        "Data Pre-processing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMp3NxIaU1Cp"
      },
      "source": [
        "# Functions that auto calibrate spacing functions\n",
        "def auto_spacing(X_dataset, y_dataset) :\n",
        "    calibrate_spcaing(X_dataset)\n",
        "    calibrate_spcaing(y_dataset)\n",
        "\n",
        "def calibrate_spcaing(context_dataset) :\n",
        "    global MECAB\n",
        "\n",
        "    for order, respondent in enumerate(context_dataset) :\n",
        "        for idx, texts in enumerate(respondent) :\n",
        "            for repairIdx, text in enumerate(texts) :\n",
        "                analyzedRes = MECAB.pos(text)\n",
        "                for mecabR in analyzedRes :\n",
        "                    # \"MAG\" == Adverb\n",
        "                    if mecabR[1] == \"MAG\" :\n",
        "                        try :\n",
        "                            startIdx = text.index(mecabR[0])\n",
        "                            if len(mecabR[0]) == 1 :\n",
        "                                if text[startIdx + 1] != \" \" and text[startIdx + 1].isalnum() : \n",
        "                                    if text[startIdx + 2] != \" \" :\n",
        "                                        text = text[:startIdx] + text[startIdx] + \" \" + text[startIdx + 1 :]\n",
        "                                        context_dataset[order][idx][repairIdx] = text\n",
        "                            else : \n",
        "                                if text[startIdx + len(mecabR[0])] != \" \" and text[startIdx + len(mecabR[0])].isalnum() : \n",
        "                                    if text[startIdx + len(mecabR[0]) + 1] != \" \" :\n",
        "                                        text = text[:startIdx] + text[startIdx : startIdx + len(mecabR[0])] + \" \" + text[startIdx + len(mecabR[0]) :]\n",
        "                                        context_dataset[order][idx][repairIdx] = text\n",
        "                        except IndexError :\n",
        "                            continue\n",
        "\n",
        "# Functions that delete stopword in sentence\n",
        "def stopword_filtering(X_dataset, y_dataset) :\n",
        "    delete_stopword(X_dataset)\n",
        "    delete_stopword(y_dataset)\n",
        "\n",
        "def delete_stopword(word_dataset) :\n",
        "    global MECAB\n",
        "\n",
        "    stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','하다']\n",
        "    for order, respondent in enumerate(word_dataset) :\n",
        "        for idx, reply in enumerate(respondent) :\n",
        "            for i, text in enumerate(reply) :\n",
        "                tokenized_data = MECAB.morphs(text)\n",
        "                tokenized_data = [word for word in tokenized_data if not word in stop_words]\n",
        "                result_text = ''.join(tokenized_data)\n",
        "                if result_text != '' : word_dataset[order][idx][i] = result_text\n",
        "\n",
        "# Functions that divide X, y dataset in learning set\n",
        "def combine_dataset(X_dataset, y_dataset) :\n",
        "    global OOT\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    for idx in range(0, DN) :\n",
        "        tmp_X = np.empty(DN)\n",
        "        tmp_y = np.empty(DN)\n",
        "        X_size = len(X_dataset[idx])\n",
        "        y_size = len(y_dataset[idx])\n",
        "\n",
        "        if X_size > y_size : \n",
        "            tmp_X = X_dataset[idx][1 : y_size + 1].flatten()\n",
        "            tmp_y = y_dataset[idx].flatten()\n",
        "        elif y_size > X_size : \n",
        "            tmp_X = X_dataset[idx].flatten()\n",
        "            tmp_y = y_dataset[idx][1 : X_size + 1].flatten()\n",
        "        else :\n",
        "            tmp_X = X_dataset[idx].flatten()\n",
        "            tmp_y = y_dataset[idx].flatten()\n",
        "\n",
        "        if idx == 0 :\n",
        "            X.append(tmp_X)\n",
        "            y.append(tmp_y)\n",
        "        elif idx == 1 :\n",
        "            # Type transformation list into ndarray\n",
        "            X = np.r_[X[0], tmp_X]\n",
        "            y = np.r_[y[0], tmp_y]\n",
        "        else :\n",
        "            X = np.r_[X, tmp_X]\n",
        "            y = np.r_[y, tmp_y]\n",
        "\n",
        "    # Set the total number of datasets to be a multiple of 10\n",
        "    if len(X) % 10 != 0 : X = X[0 : (len(X) - (len(X) % 10 ))]\n",
        "    if len(y) % 10 != 0 : y = y[0 : (len(y) - (len(y) % 10 ))]\n",
        "\n",
        "    # Nan check\n",
        "    if np.isnan(X.all()) : print(\"X dataset include NaN data\")\n",
        "    if np.isnan(y.all()) : print(\"y dataset include NaN data\")\n",
        "\n",
        "    # Reshape timestep and vector_length\n",
        "    return X.reshape(int(X.shape[0]/OOT), OOT, 1), y.reshape(int(y.shape[0]/OOT), OOT, 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lglCQxR0WGhE"
      },
      "source": [
        "Word2Vec Functions (Distributed Representation)\n",
        "*   [Word2Vec Reference 1](https://ebbnflow.tistory.com/153)\n",
        "*   [Word2Vec Reference 2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)\n",
        "\n",
        "\n",
        "*   [gensim Word2VecKeyedVectors, add](https://github.com/RaRe-Technologies/gensim/issues/2268)\n",
        "\n",
        "\n",
        "*   [PCA(sklearn) Reference](https://m.blog.naver.com/tjdrud1323/221720259834)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aaczn0GQ71N4"
      },
      "source": [
        "# Functions that draw a two-dimensional graph by entering the words, values of the two-dimensional X-axis, and values of the Y-axis.\n",
        "def plot_2d_graph(vocabs, xs, ys):\n",
        "    plt.figure(figsize=(8 ,6))\n",
        "    plt.scatter(xs, ys, marker = 'o')\n",
        "    for i, v in enumerate(vocabs):\n",
        "        plt.annotate(v, xy=(xs[i], ys[i]))\n",
        "\n",
        "# Functions that conversioning dataset to word2vec format\n",
        "def dataset_to_word2vec(X_dataset, y_dataset) :\n",
        "    return word2vec(X_dataset, True), word2vec(y_dataset, False)\n",
        "\n",
        "def word2vec(word_dataset, isXdataset) :\n",
        "    global CORPUS, OOT\n",
        "\n",
        "    result = []\n",
        "    for idx, respondent in enumerate(word_dataset) :\n",
        "        # Init words and vectors\n",
        "        w2v = Word2Vec(respondent, size=OOT, window=5, min_count=1, workers=6, sg=1)\n",
        "\n",
        "        # Set word vectors\n",
        "        if isXdataset : \n",
        "            CORPUS.add(entities=list(w2v.wv.vocab.keys()), weights=w2v.wv.vectors, replace=False)\n",
        "        vocabs = CORPUS.vocab.keys()\n",
        "        word_vector_list = [CORPUS[v] for v in vocabs]\n",
        "\n",
        "        # Confirm word similarity\n",
        "        # if \"경호\" in vocabs : print(word_vectors.most_similar(\"경호\"))\n",
        "        # else : print(word_vectors.most_similar(\"대석\"))\n",
        "        \n",
        "        pca = PCA(n_components=OOT)\n",
        "        xys = pca.fit_transform(word_vector_list)\n",
        "        xs = xys[:,0]\n",
        "        ys = xys[:,1]\n",
        "\n",
        "        # Normalization\n",
        "        scaler = MinMaxScaler()\n",
        "        scaler.fit(xys)\n",
        "        xys = scaler.transform(xys)\n",
        "\n",
        "        # Change corpus's values to normalized data\n",
        "        if isXdataset : \n",
        "            for idx, key in enumerate(vocabs) : CORPUS[[key]][0] = xys[idx]\n",
        "\n",
        "        # plot_2d_graph(vocabs, xs, ys)\n",
        "        result.append(xys.reshape(-1))\n",
        "\n",
        "    return np.array(result)\n",
        "\n",
        "def word2vec_talk(talk) :\n",
        "    global OOT\n",
        "    \n",
        "    w2v = Word2Vec(talk, size=OOT, window=5, min_count=1, workers=6, sg=1)\n",
        "\n",
        "    # Set word vectors\n",
        "    word_vectors = w2v.wv\n",
        "    vocabs = word_vectors.vocab.keys()\n",
        "    word_vector_list = [word_vectors[v] for v in vocabs]\n",
        "    \n",
        "    word_vector_list = np.asarray(word_vector_list)\n",
        "\n",
        "    # Confirm word similarity\n",
        "    # if \"경호\" in vocabs : print(word_vectors.most_similar(\"경호\"))\n",
        "    # else : print(word_vectors.most_similar(\"대석\"))\n",
        "\n",
        "    return word_vector_list.reshape(-1)\n",
        "\n",
        "# Functions that conversioning data that formed vector to word\n",
        "def vec2word(vec, isreshape=False, isvec=True, beforeWords=[]) :\n",
        "    global MECAB, CORPUS\n",
        "\n",
        "    sentence = \"\"\n",
        "    if isvec :\n",
        "        if isreshape : sentence = sentence + CORPUS.most_similar(positive=[vec.reshape(OOT,)])[0][0]\n",
        "        else : sentence = sentence + CORPUS.most_similar(positive=[vec])[0][0]\n",
        "    else :\n",
        "        word = CORPUS.most_similar(vec)[0][0]\n",
        "\n",
        "        if not word in beforeWords : sentence = sentence + word\n",
        "        else :\n",
        "            for similar in CORPUS.most_similar(vec) :\n",
        "                if not similar[0] in beforeWords :\n",
        "                    sentence = sentence + similar[0]\n",
        "                    break\n",
        "\n",
        "    stop_poses = ['SF', 'SP', 'SS', 'SO', 'NF', 'NV', 'NA', 'EF', 'EC', 'EP']\n",
        "    tokenized_data = MECAB.pos(sentence)\n",
        "    for pos in stop_poses :\n",
        "        if pos in tokenized_data[len(tokenized_data) - 1][1] : return sentence  \n",
        "\n",
        "    if not sentence in beforeWords : beforeWords.append(sentence)\n",
        "    sentence = sentence + ' ' + vec2word(sentence, isreshape=isreshape, isvec=False, beforeWords=beforeWords)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzZv5jsvHH-o"
      },
      "source": [
        "Model Learning Functions\n",
        "*   [Keras loss function Reference](https://keras.io/api/losses/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOQuvy5EHIGL"
      },
      "source": [
        "# Functions that make up the model\n",
        "def modeling_model() :\n",
        "    global model\n",
        "\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, padding='same', input_shape=(OOT, 1)))\n",
        "    model.add(MaxPooling1D(pool_size=3, padding='same'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "    model.add(MaxPooling1D(pool_size=3, padding='same'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation=\"sigmoid\")) # Performance improves once it passes through layers that have been amplified datas\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(OOT,activation=\"softmax\")) # output data == n( == y_dataset.shape[1]) things\n",
        "    model.compile(\n",
        "        loss=losses.MeanSquaredError(),\n",
        "        optimizer=Adam(learning_rate=0.0001), # pram ex. learning_rate=0.0001\n",
        "        metrics=[metrics.MeanSquaredError()]\n",
        "    )\n",
        "\n",
        "# Function to learn the configured model with the training datas\n",
        "def training_model(X_train, y_train, X_val, y_val) :\n",
        "    global model\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "          validation_data = (X_val, y_val),\n",
        "          batch_size = 20,\n",
        "          epochs = 100,\n",
        "          verbose = 1, # 0 = silent, 1 = progress bar,  2 = one line per epoch.\n",
        "          )\n",
        "    \n",
        "    return history\n",
        "    \n",
        "# Function to evaluate the learned model\n",
        "def evaluating_model(X_test, y_test, history) :\n",
        "    global model\n",
        "\n",
        "    # loss and acc graph (train and val)\n",
        "    history_df = pd.DataFrame(history.history)\n",
        "    history_df[[\"loss\", \"val_loss\"]].plot()\n",
        "\n",
        "    # Acc and Loss about real data\n",
        "    learning_lost, learning_err = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print(\"Learning error % :\", learning_err * 100)\n",
        "    print(\"Learning loss % :\", learning_lost * 100)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxjmmKaVlO9p"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea9DIOdiQ_0o"
      },
      "source": [
        "Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcHWaWjaREpT"
      },
      "source": [
        "# uploaded_files = files.upload()\n",
        "\n",
        "file_list = os.listdir('./')\n",
        "fs = [f for f in file_list if f.endswith('.txt')]\n",
        "\n",
        "talk_list = []\n",
        "DN = 0\n",
        "for f in fs :\n",
        "    \"\"\" \n",
        "    ERROR 3. ParserError: Error tokenizing data. C error \n",
        "    - Solution: add code in read_csv = , sep='\\t'\n",
        "    \"\"\"\n",
        "    talk_list.append(pd.read_csv(f, sep='\\t'))\n",
        "    DN += 1\n",
        "\n",
        "# Init Dataset\n",
        "X_dataset = []\n",
        "y_dataset = []\n",
        "\n",
        "# Data extraction\n",
        "extract_data(X_dataset, y_dataset, talk_list)\n",
        "\n",
        "# Early version is used y_list[][0] and x_list[][0] (1 word) by learning model\n",
        "unzip_replys(X_dataset, y_dataset)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG9R5wKTSNwi"
      },
      "source": [
        "Pre-processing Data\n",
        "*  [Dataset Classification Reference 1](https://ganghee-lee.tistory.com/38)\n",
        "*  [Dataset Classification Reference 2](https://ysyblog.tistory.com/69)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HENnALQjSN3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6e6be4-b10b-40c1-b6fc-5e3f0a19de08"
      },
      "source": [
        "# Space Modification\n",
        "auto_spacing(X_dataset, y_dataset)\n",
        "\n",
        "# Stopword deleted\n",
        "stopword_filtering(X_dataset, y_dataset)\n",
        "\n",
        "# Data type change on np.ndarray\n",
        "X_dataset = np.asarray(X_dataset).astype(object)\n",
        "y_dataset = np.asarray(y_dataset).astype(object)\n",
        "\n",
        "# Word2Vec on dataset\n",
        "X_dataset, y_dataset = dataset_to_word2vec(X_dataset, y_dataset)\n",
        "\n",
        "# Set learning dataset\n",
        "X_dataset, y_dataset = combine_dataset(X_dataset, y_dataset)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5KUvpUqJjwe"
      },
      "source": [
        "Model Training\n",
        "*   [NLP Reference](https://towardsdatascience.com/natural-language-processing-a-crash-course-73d7a07c240c)\n",
        "*   [Issue: Model predictional result is always same](https://github.com/keras-team/keras/issues/6447)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67l_qIoJJjVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc288bd9-5d80-4ca8-e800-15e7fb113b6a"
      },
      "source": [
        "# Data division (Train : Test = 8 : 2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size = 0.2)\n",
        "print(\"########## Train + Validation (X,) (y,) / Test (X,) (y,) ##########\")\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "# Data division (Train : Validation = 8 : 2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
        "print(\"########## Train (X,) (y,) / Validation (X,) (y,) ##########\")\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
        "\n",
        "print('\\n')\n",
        "if os.path.isfile('Aengmu.h5') : \n",
        "    # Load model\n",
        "    print('#################### Model Load... ####################')\n",
        "    model = tf.keras.models.load_model('Aengmu.h5')\n",
        "else :\n",
        "    print('#################### Init Model... ####################')\n",
        "    # Laerning model\n",
        "    model = Sequential()\n",
        "    # Modeling\n",
        "    modeling_model()\n",
        "    \n",
        "# Training\n",
        "history = training_model(X_train, y_train, X_val, y_val)\n",
        "# Evaluating\n",
        "evaluating_model(X_test, y_test, history)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Train + Validation (X,) (y,) / Test (X,) (y,) ##########\n",
            "(20315, 5, 1) (20315, 5, 1) (5079, 5, 1) (5079, 5, 1)\n",
            "########## Train (X,) (y,) / Validation (X,) (y,) ##########\n",
            "(16252, 5, 1) (16252, 5, 1) (4063, 5, 1) (4063, 5, 1)\n",
            "\n",
            "\n",
            "#################### Init Model... ####################\n",
            "Epoch 1/100\n",
            "813/813 [==============================] - 5s 5ms/step - loss: 0.1234 - mean_squared_error: 0.1234 - val_loss: 0.1107 - val_mean_squared_error: 0.1107\n",
            "Epoch 2/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.1123 - mean_squared_error: 0.1123 - val_loss: 0.1071 - val_mean_squared_error: 0.1071\n",
            "Epoch 3/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.1062 - mean_squared_error: 0.1062 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
            "Epoch 4/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.1009 - mean_squared_error: 0.1009 - val_loss: 0.0958 - val_mean_squared_error: 0.0958\n",
            "Epoch 5/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0985 - mean_squared_error: 0.0985 - val_loss: 0.0945 - val_mean_squared_error: 0.0945\n",
            "Epoch 6/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0971 - mean_squared_error: 0.0971 - val_loss: 0.0930 - val_mean_squared_error: 0.0930\n",
            "Epoch 7/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0955 - mean_squared_error: 0.0955 - val_loss: 0.0915 - val_mean_squared_error: 0.0915\n",
            "Epoch 8/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0945 - mean_squared_error: 0.0945 - val_loss: 0.0908 - val_mean_squared_error: 0.0908\n",
            "Epoch 9/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0937 - mean_squared_error: 0.0937 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
            "Epoch 10/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0933 - mean_squared_error: 0.0933 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
            "Epoch 11/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0929 - mean_squared_error: 0.0929 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
            "Epoch 12/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0925 - mean_squared_error: 0.0925 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
            "Epoch 13/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0923 - mean_squared_error: 0.0923 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
            "Epoch 14/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0921 - mean_squared_error: 0.0921 - val_loss: 0.0895 - val_mean_squared_error: 0.0895\n",
            "Epoch 15/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0920 - mean_squared_error: 0.0920 - val_loss: 0.0894 - val_mean_squared_error: 0.0894\n",
            "Epoch 16/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0918 - mean_squared_error: 0.0918 - val_loss: 0.0894 - val_mean_squared_error: 0.0894\n",
            "Epoch 17/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0917 - mean_squared_error: 0.0917 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
            "Epoch 18/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0916 - mean_squared_error: 0.0916 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
            "Epoch 19/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0916 - mean_squared_error: 0.0916 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
            "Epoch 20/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0915 - mean_squared_error: 0.0915 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
            "Epoch 21/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0914 - mean_squared_error: 0.0914 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
            "Epoch 22/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0914 - mean_squared_error: 0.0914 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
            "Epoch 23/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0914 - mean_squared_error: 0.0914 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
            "Epoch 24/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0913 - mean_squared_error: 0.0913 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
            "Epoch 25/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0913 - mean_squared_error: 0.0913 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
            "Epoch 26/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
            "Epoch 27/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
            "Epoch 28/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 29/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 30/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 31/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 32/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 33/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 34/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 35/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 36/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 37/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 38/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 39/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 40/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 41/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 42/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 43/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 44/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 45/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 46/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 47/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 48/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 49/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 50/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 51/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 52/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
            "Epoch 53/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 54/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 55/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 56/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 57/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 58/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 59/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 60/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 61/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 62/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0909 - mean_squared_error: 0.0909 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 63/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 64/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 65/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 66/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 67/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 68/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 69/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 70/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 71/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 72/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 73/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 74/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 75/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 76/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 77/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 78/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 79/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 80/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 81/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 82/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 83/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 84/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 85/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 86/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 87/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 88/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 89/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 90/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 91/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 92/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 93/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 94/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 95/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 96/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 97/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 98/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 99/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "Epoch 100/100\n",
            "813/813 [==============================] - 4s 5ms/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
            "159/159 - 0s - loss: 0.0902 - mean_squared_error: 0.0902\n",
            "Learning error % : 9.022875875234604\n",
            "Learning loss % : 9.022875875234604\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_24 (Conv1D)           (None, 5, 64)             256       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_24 (MaxPooling (None, 2, 64)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_25 (Conv1D)           (None, 2, 64)             12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_25 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 17,093\n",
            "Trainable params: 17,093\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA4mqS5DTpn5"
      },
      "source": [
        "Prediction (Talk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk3zCKMclQz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa5d079-2168-48a7-f4db-a7e5b0d6f05b"
      },
      "source": [
        "while True :\n",
        "    try :\n",
        "        talk = input(\"앵무에게 보낼 카톡: \")\n",
        "\n",
        "        if talk == \"\" : \n",
        "            print(\"대화 종료\")\n",
        "            break\n",
        "\n",
        "        talk_vec = word2vec_talk([talk])\n",
        "        talk_vec = talk_vec.reshape(int(talk_vec.shape[0]/OOT), OOT, 1)\n",
        "        Aengmu = model.predict(talk_vec)\n",
        "\n",
        "        print('앵무: ' + vec2word(Aengmu[len(Aengmu) - 1]) + '\\n')\n",
        "    except ValueError :\n",
        "        print(\"ERROR, code 00001\")\n",
        "        break"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "앵무에게 보낼 카톡: 안녕\n",
            "앵무: 달거싶은데\n",
            "\n",
            "앵무에게 보낼 카톡: 오랜만이야\n",
            "앵무: 좋은데야지 비싸지지않냐\n",
            "\n",
            "앵무에게 보낼 카톡: 오\n",
            "앵무: 자부렷다\n",
            "\n",
            "앵무에게 보낼 카톡: 제대로 말하긴 하네 이제\n",
            "앵무: ㅜㅜ 같은데\n",
            "\n",
            "앵무에게 보낼 카톡: \n",
            "대화 종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0_MpEIFjCOK"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JpataRYhQAr"
      },
      "source": [
        "#model.save('Aengmu.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}